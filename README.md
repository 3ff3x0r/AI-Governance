# AI-Governance
Project for AI Governance Course


Artificial Intelligence (AI) has a longstanding history of overpromising, often leading to public disillusionment when advancements fall short of initial expectations. One of the earliest and most well-known examples occurred in the 1960s, when researchers working on artificial neural networks (ANNs) made ambitious, headline-grabbing predictions about the potential of their field. At the time, there was widespread optimism that within a decade, AI systems would achieve human-like abilities, including natural language processing, computer vision, and the ability to perform complex physical tasks, such as walking and navigating the real world (McCorduck, 2004; Russell & Norvig, 2016). However, these projections proved to be overly optimistic, and despite recent remarkable progress in areas like deep learning, it has taken over half a century to partially realize the goals envisioned by early AI pioneers. 

Periods of unfulfilled expectations in AI often lead to diminished public trust and reduced enthusiasm, which can make it challenging to sustain funding and institutional support for further advancements (Floridi et al., 2018). This phenomenon, often referred to as an “AI winter,” reflects the cyclical nature of public optimism and skepticism surrounding the field. On the other hand, breakthroughs in areas like natural language processing and computer vision have recently reignited public interest, sometimes generating excessive optimism about the scalability and transformative potential of current technologies. It has become increasingly common to encounter claims that AI could, within a few years, address complex global challenges such as climate change or discover cures for diseases that have long eluded medical research (Marcus & Davis, 2019). However, alongside this optimism, there are also growing ethical concerns and debates about the potential risks posed by these technologies, with some philosophers and ethicists cautioning against the unrestrained development of AI due to its possible social and existential impacts (Bostrom, 2014; Russell, 2019).

It is widely anticipated that AI will have a profound and possibly transformative impact on society, though the precise nature and extent of these changes remain uncertain. While some scholars and futurists suggest AI could help create a post-scarcity society, where individuals can engage more fully in creative and meaningful pursuits (Mason, 2015), others warn of a potential exacerbation of economic inequality, predicting an even wider gap between socioeconomic classes (Susskind, 2020). There are also more extreme perspectives that envision catastrophic outcomes, where advanced AI systems could pose existential risks or fundamentally alter human civilization in unforeseen ways (Bostrom, 2014).

In the midst of these perspectives, regulatory proposals and legislation aim to foster a future where emerging technologies can develop responsibly. Such initiatives seek to balance the U.S.'s competitive edge in global innovation with safeguards that ensure these technologies do not harmfully disrupt other industries or compromise public welfare. California, as the heart of the U.S. technology sector, plays a pivotal role in these discussions. The state is home to many leading AI companies and research institutions, positioning it uniquely to influence both the development and oversight of AI technologies on a national and international scale.


----
# References (not in order)
1. Mason, P. (2015). *Postcapitalism: A Guide to Our Future*. Discusses the potential for technology, including AI, to create a society less reliant on traditional economic scarcity.
2. Susskind, D. (2020). *A World Without Work: Technology, Automation, and How We Should Respond*. Explores the implications of automation on socioeconomic divisions and the future of work.
3. Bostrom, N. (2014). *Superintelligence: Paths, Dangers, Strategies*. Examines existential risks associated with advanced AI systems.
4. Brynjolfsson, E., & McAfee, A. (2014). *The Second Machine Age: Work, Progress, and Prosperity in a Time of Brilliant Technologies*. Analyzes how AI and other technologies might affect the future of work and economic inequality.
5. Russell, S. (2019). *Human Compatible: Artificial Intelligence and the Problem of Control*. Offers insights into the broader societal risks associated with AI development.
6. Floridi, L., Cowls, J., King, T. C., & Taddeo, M. (2018). *How to Design AI for Social Good: Seven Essential Factors*. This paper discusses the societal impacts and ethical considerations surrounding AI, especially when expectations are not met.
7. Marcus, G., & Davis, E. (2019). *Rebooting AI: Building Artificial Intelligence We Can Trust*. Discusses the limitations and overpromises often seen in AI hype, especially in relation to solving complex problems.
8. Bostrom, N. (2014). *Superintelligence: Paths, Dangers, Strategies*. Provides insight into the potential risks posed by AI from a philosophical and existential standpoint.
9. Russell, S. (2019). *Human Compatible: Artificial Intelligence and the Problem of Control*. Examines the risks and ethical implications of advancing AI technologies. 
10. McCorduck, P. (2004). *Machines Who Think*. A detailed exploration of the history of AI and its recurring cycles of hype and disappointment.
11. Russell, S., & Norvig, P. (2016). *Artificial Intelligence: A Modern Approach*. Provides an overview of the field's advancements and the historical context of AI's challenges.

---
# Notes/Brainstorm to the continuing the text
1. Fears of corrupt regulations
Pirate Wires
The Conflict of Interest at the Heart of CA’s AI Bill
https://www.piratewires.com/p/sb-1047-dan-hendrycks-conflict-of-interest
